{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "nan",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3361\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3361\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3362\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:76\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:108\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: nan",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\桌面\\车货匹配\\不同场景不同目标函数相关\\实际数据\\MVMC\\MVMC.ipynb 单元格 1\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/%E8%BD%A6%E8%B4%A7%E5%8C%B9%E9%85%8D/%E4%B8%8D%E5%90%8C%E5%9C%BA%E6%99%AF%E4%B8%8D%E5%90%8C%E7%9B%AE%E6%A0%87%E5%87%BD%E6%95%B0%E7%9B%B8%E5%85%B3/%E5%AE%9E%E9%99%85%E6%95%B0%E6%8D%AE/MVMC/MVMC.ipynb#W0sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m \u001b[39m# 如果该组匹配已经出现过，则直接跳出内层for循环\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/%E8%BD%A6%E8%B4%A7%E5%8C%B9%E9%85%8D/%E4%B8%8D%E5%90%8C%E5%9C%BA%E6%99%AF%E4%B8%8D%E5%90%8C%E7%9B%AE%E6%A0%87%E5%87%BD%E6%95%B0%E7%9B%B8%E5%85%B3/%E5%AE%9E%E9%99%85%E6%95%B0%E6%8D%AE/MVMC/MVMC.ipynb#W0sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/%E8%BD%A6%E8%B4%A7%E5%8C%B9%E9%85%8D/%E4%B8%8D%E5%90%8C%E5%9C%BA%E6%99%AF%E4%B8%8D%E5%90%8C%E7%9B%AE%E6%A0%87%E5%87%BD%E6%95%B0%E7%9B%B8%E5%85%B3/%E5%AE%9E%E9%99%85%E6%95%B0%E6%8D%AE/MVMC/MVMC.ipynb#W0sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     matching_type \u001b[39m=\u001b[39m type_matching\u001b[39m.\u001b[39;49mloc[vehicles_df[\u001b[39m'\u001b[39;49m\u001b[39mtype\u001b[39;49m\u001b[39m'\u001b[39;49m][i]\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39;49m\u001b[39m_\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m0\u001b[39;49m], cargo_df[\u001b[39m'\u001b[39;49m\u001b[39mtype\u001b[39;49m\u001b[39m'\u001b[39;49m][j]]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/%E8%BD%A6%E8%B4%A7%E5%8C%B9%E9%85%8D/%E4%B8%8D%E5%90%8C%E5%9C%BA%E6%99%AF%E4%B8%8D%E5%90%8C%E7%9B%AE%E6%A0%87%E5%87%BD%E6%95%B0%E7%9B%B8%E5%85%B3/%E5%AE%9E%E9%99%85%E6%95%B0%E6%8D%AE/MVMC/MVMC.ipynb#W0sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m     matched_pairs\u001b[39m.\u001b[39madd((i,j)) \u001b[39m# 将该组匹配加入已匹配组合的集合中\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/%E8%BD%A6%E8%B4%A7%E5%8C%B9%E9%85%8D/%E4%B8%8D%E5%90%8C%E5%9C%BA%E6%99%AF%E4%B8%8D%E5%90%8C%E7%9B%AE%E6%A0%87%E5%87%BD%E6%95%B0%E7%9B%B8%E5%85%B3/%E5%AE%9E%E9%99%85%E6%95%B0%E6%8D%AE/MVMC/MVMC.ipynb#W0sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     a1[i, j] \u001b[39m=\u001b[39m matching_type\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:925\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    923\u001b[0m         \u001b[39mwith\u001b[39;00m suppress(\u001b[39mKeyError\u001b[39;00m, \u001b[39mIndexError\u001b[39;00m):\n\u001b[0;32m    924\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[1;32m--> 925\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[0;32m    926\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    927\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m    928\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1100\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_getitem_tuple\u001b[39m(\u001b[39mself\u001b[39m, tup: \u001b[39mtuple\u001b[39m):\n\u001b[0;32m   1099\u001b[0m     \u001b[39mwith\u001b[39;00m suppress(IndexingError):\n\u001b[1;32m-> 1100\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_lowerdim(tup)\n\u001b[0;32m   1102\u001b[0m     \u001b[39m# no multi-index, so validate all of the indexers\u001b[39;00m\n\u001b[0;32m   1103\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_valid_tuple(tup)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:862\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[39mreturn\u001b[39;00m section\n\u001b[0;32m    861\u001b[0m         \u001b[39m# This is an elided recursive call to iloc/loc\u001b[39;00m\n\u001b[1;32m--> 862\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(section, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)[new_key]\n\u001b[0;32m    864\u001b[0m \u001b[39mraise\u001b[39;00m IndexingError(\u001b[39m\"\u001b[39m\u001b[39mnot applicable\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:931\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    928\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m    930\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[1;32m--> 931\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1164\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1162\u001b[0m \u001b[39m# fall thru to straight lookup\u001b[39;00m\n\u001b[0;32m   1163\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m-> 1164\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_label(key, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1113\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1111\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_label\u001b[39m(\u001b[39mself\u001b[39m, label, axis: \u001b[39mint\u001b[39m):\n\u001b[0;32m   1112\u001b[0m     \u001b[39m# GH#5667 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[1;32m-> 1113\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49mxs(label, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3776\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   3774\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected label or tuple of labels, got \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m   3775\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 3776\u001b[0m     loc \u001b[39m=\u001b[39m index\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3778\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(loc, np\u001b[39m.\u001b[39mndarray):\n\u001b[0;32m   3779\u001b[0m         \u001b[39mif\u001b[39;00m loc\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mbool_:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3363\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3362\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3363\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3365\u001b[0m \u001b[39mif\u001b[39;00m is_scalar(key) \u001b[39mand\u001b[39;00m isna(key) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhasnans:\n\u001b[0;32m   3366\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: nan"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.optimize import linprog\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "from pulp import *\n",
    "import csv\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "# 读取货物和车辆的数据\n",
    "cargo_df = pd.read_csv('cargo - dd.csv')\n",
    "vehicles_df = pd.read_csv('vehicles - dd.csv')\n",
    "type_matching_df = pd.read_csv('Type_matching.csv')\n",
    "\n",
    "\n",
    "def haversine_distance(point1, point2):\n",
    "    lat1, lon1 = point1\n",
    "    lat2, lon2 = point2\n",
    "    R = 6371  # 地球半径，单位km\n",
    "    dlat = radians(lat2 - lat1)\n",
    "    dlon = radians(lon2 - lon1)\n",
    "    a = sin(dlat / 2) ** 2 + cos(radians(lat1)) * cos(radians(lat2)) * sin(dlon / 2) ** 2\n",
    "    c0 = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    distance = R * c0\n",
    "    return distance\n",
    "\n",
    "# 定义模型参数\n",
    "w1, w2, w3, w4 = 0.36, 0.11, 0.18, 0.35\n",
    "n_vehicles = len(vehicles_df)\n",
    "n_cargo = len(cargo_df)\n",
    "cargo_types = cargo_df['type'].values\n",
    "cargo_weights = cargo_df['w_j^c'].values\n",
    "cargo_volumes = cargo_df['v_j^c'].values\n",
    "cargo_origins = list(zip(cargo_df['lat_j^c1'].values, cargo_df['lon_j^c1'].values))\n",
    "cargo_destinations = list(zip(cargo_df['lat_j^c2'].values, cargo_df['lon_j^c2'].values))\n",
    "cargo_pickup_times = pd.to_datetime(cargo_df['t_j^c1'], format='%Y/%m/%d %H:%M').values\n",
    "cargo_delivery_times = pd.to_datetime(cargo_df['t_j^c2'], format='%Y/%m/%d %H:%M').values\n",
    "cargo_fees = cargo_df['f_j^c'].values\n",
    "vehicle_types = vehicles_df['type'].values\n",
    "vehicle_weights = vehicles_df['w_i^v'].values\n",
    "vehicle_volumes = vehicles_df['v_i^v'].values\n",
    "vehicle_latitudes = vehicles_df['lat_i^v'].values\n",
    "vehicle_longitudes = vehicles_df['lon_i^v'].values\n",
    "cargo_indexes = np.arange(n_cargo)\n",
    "vehicle_indexes = np.arange(n_vehicles)\n",
    "\n",
    "# 计算车辆和货物之间的匹配度a1\n",
    "matched_pairs = set() # 创建一个空的集合\n",
    "type_matching = type_matching_df.pivot(index='type_i^v', columns='type_j^c', values='num').fillna(0)\n",
    "a1 = np.zeros((n_vehicles, n_cargo))\n",
    "for i in range(n_vehicles):\n",
    "    for j in range(n_cargo):\n",
    "        if (i,j) in matched_pairs:\n",
    "            break # 如果该组匹配已经出现过，则直接跳出内层for循环\n",
    "        else:\n",
    "            matching_type = type_matching.loc[vehicles_df['type'][i].split('_')[0], cargo_df['type'][j]]\n",
    "            matched_pairs.add((i,j)) # 将该组匹配加入已匹配组合的集合中\n",
    "            a1[i, j] = matching_type\n",
    "            if matching_type == 0:\n",
    "                a1[i, j] = 0\n",
    "                break  # 直接跳出内层for循环\n",
    "\n",
    "# 计算车辆和货物之间的匹配度a2\n",
    "a2 = np.zeros((n_vehicles, n_cargo))\n",
    "for i in range(n_vehicles):\n",
    "    for j in range(n_cargo):\n",
    "            # 检查重量和体积是否符合要求\n",
    "            if cargo_weights[j] <= vehicle_weights[i] and cargo_volumes[j] <= vehicle_volumes[i]:\n",
    "                a2[i, j] = round(max(1 - ((vehicle_weights[i] - cargo_weights[j]) / vehicle_weights[i]), 1 - ((vehicle_volumes[i] - cargo_volumes[j]) / vehicle_volumes[i])), 2)\n",
    "                matched_pairs.add((i, j))\n",
    "            else:\n",
    "                a2[i, j] = 0\n",
    "\n",
    "# 计算车辆和货物之间的匹配度a3、a4\n",
    "a3 = np.zeros((n_vehicles, n_cargo))\n",
    "a4 = np.zeros((n_vehicles,n_cargo))\n",
    "z = np.zeros((n_vehicles, n_cargo))\n",
    "e = np.zeros((n_vehicles,n_cargo))\n",
    "p = np.zeros((n_vehicles,n_cargo))\n",
    "c = np.zeros((n_vehicles,n_cargo))\n",
    "dist1 = np.zeros((n_vehicles,n_cargo))\n",
    "dist2 = np.zeros((n_vehicles,n_cargo))\n",
    "time1 = np.zeros((n_vehicles,n_cargo))\n",
    "time2 = np.zeros((n_vehicles,n_cargo))\n",
    "total_time = np.zeros((n_vehicles,n_cargo))\n",
    "delta = np.timedelta64(1, 's')\n",
    "for i in range(n_vehicles):\n",
    "    for j in range(n_cargo):\n",
    "            # 计算距离和时间\n",
    "            dist1[i, j] = haversine_distance((vehicle_latitudes[i], vehicle_longitudes[i]), cargo_origins[j])\n",
    "            dist2[i, j] = haversine_distance(cargo_origins[j], cargo_destinations[j])\n",
    "            time1[i, j] = dist1[i, j] / 40\n",
    "            time2[i, j] = dist2[i, j] / 80\n",
    "            total_time[i, j] = time1[i, j] + time2[i, j] + 3\n",
    "            # 检查时间是否符合要求\n",
    "         \n",
    "            time_diff_seconds = (cargo_delivery_times[j] - cargo_pickup_times[j]) / delta\n",
    "            if total_time[i, j] <= time_diff_seconds / 3600:\n",
    "                a3[i, j] = round(total_time[i, j] / (time_diff_seconds / (3600 * 2)), 2)\n",
    "                a4[i, j] = round(dist2[i, j] / (dist1[i, j] + dist2[i, j]), 2)\n",
    "                matched_pairs.add((i, j))\n",
    "            else:\n",
    "                a3[i, j] = 0\n",
    "                break\n",
    "\n",
    "b = 1.92\n",
    "u = 0.5\n",
    "c[i, j] = u * dist1[i, j] + b * (cargo_weights[j] / vehicle_weights[i]) * u * dist2[i, j]\n",
    "\n",
    "# 循环检查每个匹配对\n",
    "for i in range(n_vehicles):\n",
    "    for j in range(n_cargo):\n",
    "        # 检查个匹配度是否为零\n",
    "        if np.any([a1[i, j] == 0, a2[i, j] == 0, a3[i, j] == 0]):\n",
    "            e[i, j] = z[i, j] = p[i, j] = a4[i, j] = 0\n",
    "        else:\n",
    "            a4[i, j] = round(dist2[i, j] / (dist1[i, j] + dist2[i, j]), 2)\n",
    "            z[i, j] = round((w1 * a1[i, j] + w2 * a2[i, j] + w3 * a3[i, j] + w4 * a4[i, j]), 2)\n",
    "            e[i, j] = round((cargo_fees[j] - c[i, j]) / (total_time[i, j] + 3), 2)\n",
    "            p[i, j] = round((cargo_fees[j] - c[i, j]), 2)\n",
    "\n",
    "z[i, j] = w1 * a1[i, j] + w2 * a2[i, j] + w3 * a3[i, j] + w4 * a4[i, j]\n",
    "# 输出z矩阵\n",
    "print(\"z矩阵:\")\n",
    "print(z)\n",
    "\n",
    "\n",
    "# 将z矩阵保存在z_matrix全局变量中\n",
    "z_matrix = z\n",
    "e_matrix = e\n",
    "a4_matrix = a4\n",
    "p_matrix = p\n",
    "# 定义some_function函数\n",
    "def some_function():\n",
    "    global e_matrix\n",
    "    # 在函数内部对z_matrix做一些处理或者调用其他函数\n",
    "    # ...\n",
    "\n",
    "# 在后续代码中调用some_function函数\n",
    "some_function()\n",
    "\n",
    "\n",
    "matching_matrix = e_matrix\n",
    "\n",
    "\n",
    "\n",
    "# 使用Kuhn-Munkres算法求解车辆和货物匹配问题\n",
    "row_ind, col_ind = linear_sum_assignment(-matching_matrix)\n",
    "matching = np.column_stack((row_ind, col_ind))\n",
    "\n",
    "# 输出车辆和货物匹配的结果到csv文件\n",
    "e_sum = 0\n",
    "k_sum = 0\n",
    "p_sum = 0\n",
    "d_sum = 0\n",
    "count = 0\n",
    "\n",
    "with open('MVMC_z2_matches.csv', mode='w', encoding='utf-8-sig', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Vehicle', 'Cargo', 'Match', 'PVI', 'EDRI', 'PI', 'PCLDI'])\n",
    "    \n",
    "    for vehicle, cargo in matching:\n",
    "        writer.writerow([vehicle, cargo, 'Yes', e[vehicle][cargo], 1 - a4[vehicle][cargo], p[vehicle][cargo], 1 - a1[vehicle][cargo]])\n",
    "        \n",
    "        # 累加\"E\"和\"K\"的值\n",
    "        e_sum += e[vehicle][cargo]\n",
    "        k_sum += 1 - a4[vehicle][cargo]\n",
    "        p_sum += p[vehicle][cargo]\n",
    "        d_sum += 1 - a1[vehicle][cargo]\n",
    "        count += 1\n",
    "    \n",
    "    # 计算\"E\"和\"K\"的平均值\n",
    "    e_mean = e_sum / count\n",
    "    k_mean = k_sum / count\n",
    "    p_mean = p_sum / count\n",
    "    d_mean = d_sum / count\n",
    "    # 写入\"E\"和\"K\"的平均值到CSV文件的对应列的最下方\n",
    "    writer.writerow(['Average', 'Average', '', e_mean, k_mean, p_mean, d_mean]) \n",
    "\n",
    "# 定义some_function函数\n",
    "def some_function():\n",
    "    global a4_matrix\n",
    "    # 在函数内部对z_matrix做一些处理或者调用其他函数\n",
    "    # ...\n",
    "\n",
    "# 在后续代码中调用some_function函数\n",
    "some_function()\n",
    "\n",
    "\n",
    "matching_matrix = a4_matrix\n",
    "\n",
    "\n",
    "\n",
    "# 使用Kuhn-Munkres算法求解车辆和货物匹配问题\n",
    "row_ind, col_ind = linear_sum_assignment(-matching_matrix)\n",
    "matching = np.column_stack((row_ind, col_ind))\n",
    "\n",
    "# 输出车辆和货物匹配的结果到csv文件\n",
    "e_sum = 0\n",
    "k_sum = 0\n",
    "p_sum = 0\n",
    "d_sum = 0\n",
    "count = 0\n",
    "\n",
    "with open('MVMC_z3_matches.csv', mode='w', encoding='utf-8-sig', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Vehicle', 'Cargo', 'Match', 'PVI', 'EDRI', 'PI', 'PCLDI'])\n",
    "    \n",
    "    for vehicle, cargo in matching:\n",
    "        writer.writerow([vehicle, cargo, 'Yes', e[vehicle][cargo], 1 - a4[vehicle][cargo], p[vehicle][cargo], 1 - a1[vehicle][cargo]])\n",
    "        \n",
    "        # 累加\"E\"和\"K\"的值\n",
    "        e_sum += e[vehicle][cargo]\n",
    "        k_sum += 1 - a4[vehicle][cargo]\n",
    "        p_sum += p[vehicle][cargo]\n",
    "        d_sum += 1 - a1[vehicle][cargo]\n",
    "        count += 1\n",
    "    \n",
    "    # 计算\"E\"和\"K\"的平均值\n",
    "    e_mean = e_sum / count\n",
    "    k_mean = k_sum / count\n",
    "    p_mean = p_sum / count\n",
    "    d_mean = d_sum / count\n",
    "    # 写入\"E\"和\"K\"的平均值到CSV文件的对应列的最下方\n",
    "    writer.writerow(['Average', 'Average', '', e_mean, k_mean, p_mean, d_mean])  \n",
    "\n",
    "# 定义some_function函数\n",
    "def some_function():\n",
    "    global p_matrix\n",
    "    # 在函数内部对z_matrix做一些处理或者调用其他函数\n",
    "    # ...\n",
    "\n",
    "# 在后续代码中调用some_function函数\n",
    "some_function()\n",
    "\n",
    "\n",
    "matching_matrix = p_matrix\n",
    "\n",
    "\n",
    "\n",
    "# 使用Kuhn-Munkres算法求解车辆和货物匹配问题\n",
    "row_ind, col_ind = linear_sum_assignment(-matching_matrix)\n",
    "matching = np.column_stack((row_ind, col_ind))\n",
    "\n",
    "# 输出车辆和货物匹配的结果到csv文件\n",
    "e_sum = 0\n",
    "k_sum = 0\n",
    "p_sum = 0\n",
    "d_sum = 0\n",
    "count = 0\n",
    "\n",
    "with open('MVMC_z1_matches.csv', mode='w', encoding='utf-8-sig', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Vehicle', 'Cargo', 'Match', 'PVI', 'EDRI', 'PI', 'PCLDI'])\n",
    "    \n",
    "    for vehicle, cargo in matching:\n",
    "        writer.writerow([vehicle, cargo, 'Yes', e[vehicle][cargo], 1 - a4[vehicle][cargo], p[vehicle][cargo], 1 - a1[vehicle][cargo]])\n",
    "        \n",
    "        # 累加\"E\"和\"K\"的值\n",
    "        e_sum += e[vehicle][cargo]\n",
    "        k_sum += 1 - a4[vehicle][cargo]\n",
    "        p_sum += p[vehicle][cargo]\n",
    "        d_sum += 1 - a1[vehicle][cargo]\n",
    "        count += 1\n",
    "    \n",
    "    # 计算\"E\"和\"K\"的平均值\n",
    "    e_mean = e_sum / count\n",
    "    k_mean = k_sum / count\n",
    "    p_mean = p_sum / count\n",
    "    d_mean = d_sum / count\n",
    "    # 写入\"E\"和\"K\"的平均值到CSV文件的对应列的最下方\n",
    "    writer.writerow(['Average', 'Average', '', e_mean, k_mean, p_mean, d_mean]) \n",
    "\n",
    "# 定义some_function函数\n",
    "def some_function():\n",
    "    global z_matrix\n",
    "    # 在函数内部对z_matrix做一些处理或者调用其他函数\n",
    "    # ...\n",
    "\n",
    "# 在后续代码中调用some_function函数\n",
    "some_function()\n",
    "\n",
    "\n",
    "matching_matrix = z_matrix\n",
    "\n",
    "\n",
    "\n",
    "# 使用Kuhn-Munkres算法求解车辆和货物匹配问题\n",
    "row_ind, col_ind = linear_sum_assignment(-matching_matrix)\n",
    "matching = np.column_stack((row_ind, col_ind))\n",
    "\n",
    "# 输出车辆和货物匹配的结果到csv文件\n",
    "e_sum = 0\n",
    "k_sum = 0\n",
    "p_sum = 0\n",
    "d_sum = 0\n",
    "count = 0\n",
    "\n",
    "with open('MVMC_z4_matches.csv', mode='w', encoding='utf-8-sig', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Vehicle', 'Cargo', 'Match', 'PVI', 'EDRI', 'PI', 'PCLDI'])\n",
    "    \n",
    "    for vehicle, cargo in matching:\n",
    "        writer.writerow([vehicle, cargo, 'Yes', e[vehicle][cargo], 1 - a4[vehicle][cargo], p[vehicle][cargo], 1 - a1[vehicle][cargo]])\n",
    "        \n",
    "        # 累加\"E\"和\"K\"的值\n",
    "        e_sum += e[vehicle][cargo]\n",
    "        k_sum += 1 - a4[vehicle][cargo]\n",
    "        p_sum += p[vehicle][cargo]\n",
    "        d_sum += 1 - a1[vehicle][cargo]\n",
    "        count += 1\n",
    "    \n",
    "    # 计算\"E\"和\"K\"的平均值\n",
    "    e_mean = e_sum / count\n",
    "    k_mean = k_sum / count\n",
    "    p_mean = p_sum / count\n",
    "    d_mean = d_sum / count\n",
    "    # 写入\"E\"和\"K\"的平均值到CSV文件的对应列的最下方\n",
    "    writer.writerow(['Average', 'Average', '', e_mean, k_mean, p_mean, d_mean])  \n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 读取数据\n",
    "p_data = pd.read_csv('MVMC_z1_matches.csv')['PVI'].iloc[:-1].tolist()\n",
    "e_data = pd.read_csv('MVMC_z2_matches.csv')['PVI'].iloc[:-1].tolist()\n",
    "k_data = pd.read_csv('MVMC_z3_matches.csv')['PVI'].iloc[:-1].tolist()\n",
    "z_data = pd.read_csv('MVMC_z4_matches.csv')['PVI'].iloc[:-1].tolist()\n",
    "\n",
    "# 绘制箱线图\n",
    "data = [p_data, e_data, k_data, z_data]\n",
    "labels = ['Z_1', 'Z_2', 'Z_3', 'Z_4']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10, 8))\n",
    "\n",
    "# 第一个子图\n",
    "ax1 = axes[0, 0]\n",
    "ax1.boxplot(data)\n",
    "ax1.set_xticklabels(labels)\n",
    "ax1.set_xlabel('Functions')\n",
    "ax1.set_ylabel('')\n",
    "ax1.set_title('PVI')\n",
    "\n",
    "# 第二个子图\n",
    "p_data = pd.read_csv('MVMC_z1_matches.csv')['EDRI'].iloc[:-1].tolist()\n",
    "e_data = pd.read_csv('MVMC_z2_matches.csv')['EDRI'].iloc[:-1].tolist()\n",
    "k_data = pd.read_csv('MVMC_z3_matches.csv')['EDRI'].iloc[:-1].tolist()\n",
    "z_data = pd.read_csv('MVMC_z4_matches.csv')['EDRI'].iloc[:-1].tolist()\n",
    "data = [p_data, e_data, k_data, z_data]\n",
    "ax2 = axes[0, 1]\n",
    "ax2.boxplot(data)\n",
    "ax2.set_xticklabels(labels)\n",
    "ax2.set_xlabel('Functions')\n",
    "ax2.set_ylabel('')\n",
    "ax2.set_title('EDRI')\n",
    "\n",
    "# 第三个子图\n",
    "p_data = pd.read_csv('MVMC_z1_matches.csv')['PI'].iloc[:-1].tolist()\n",
    "e_data = pd.read_csv('MVMC_z2_matches.csv')['PI'].iloc[:-1].tolist()\n",
    "k_data = pd.read_csv('MVMC_z3_matches.csv')['PI'].iloc[:-1].tolist()\n",
    "z_data = pd.read_csv('MVMC_z4_matches.csv')['PI'].iloc[:-1].tolist()\n",
    "data = [p_data, e_data, k_data, z_data]\n",
    "ax3 = axes[1, 0]\n",
    "ax3.boxplot(data)\n",
    "ax3.set_xticklabels(labels)\n",
    "ax3.set_xlabel('Functions')\n",
    "ax3.set_ylabel('')\n",
    "ax3.set_title('PI')\n",
    "\n",
    "# 第四个子图\n",
    "p_data = pd.read_csv('MVMC_z1_matches.csv')['PCLDI'].iloc[:-1].tolist()\n",
    "e_data = pd.read_csv('MVMC_z2_matches.csv')['PCLDI'].iloc[:-1].tolist()\n",
    "k_data = pd.read_csv('MVMC_z3_matches.csv')['PCLDI'].iloc[:-1].tolist()\n",
    "z_data = pd.read_csv('MVMC_z4_matches.csv')['PCLDI'].iloc[:-1].tolist()\n",
    "data = [p_data, e_data, k_data, z_data]\n",
    "ax4 = axes[1, 1]\n",
    "ax4.boxplot(data)\n",
    "ax4.set_xticklabels(labels)\n",
    "ax4.set_xlabel('Functions')\n",
    "ax4.set_ylabel('')\n",
    "ax4.set_title('PCLDI')\n",
    "\n",
    "# 调整子图之间的间距\n",
    "plt.tight_layout()\n",
    "\n",
    "# 显示图形\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
